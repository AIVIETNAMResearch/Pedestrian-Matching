image_root: 'data/RSTPReid/imgs'
train_file: ['data/RSTPReid/processed_data/train.json']
val_file: 'data/RSTPReid/processed_data/test.json'

test_file: 'data/RSTPReid/processed_data/test.json'


## Vision Encoder
use_beit_v2: True
vision_config: 'configs/config_beit2_base.json'
image_res: 384
patch_size: 16
embed_dim: 256

use_momentum: True
momentum: 0.995

temp: 0.07

## Text Encoder (& Cross Encoder)
text_encoder: 'configs/bert-base-uncased'
text_tokenizer: 'bert-base-uncased'

text_num_hidden_layers: 18
text_fusion_start_at: 12

## Training
num_dec_layers: 6
large_lr_for_dec: True
batch_size_train: 46
accumulate_steps: 1
batch_size_test_text: 64
batch_size_test: 64
max_tokens: 40
k_test: 64

use_sdm: False
use_id_loss: False

# num_classes: 11003

# MLM
mlm: True
max_words: 30
mask_prob: 0.5
max_masks: 12
mask_whole_word: True
skipgram_prb: 0.2
skipgram_size: 3

erasing_p: 0.6

## Other Settings
optimizer: {opt: adamW, lr: 1e-5, weight_decay: 0.01, lr_mult: 2, vision_lr: 1e-5, text_lr: 1e-5}
schedular: {sched: cosine, epochs: 31, num_warmup_steps: 0.025}
eval_epoch: 3  # epoch index


# cross augmentation

# # fm_batch
# use_cross_aug: False
# cross_prob: 0.7
# cross_gene: 0.01
# cross_kernel_size: 3
# cross_max_features: 2

# fm inverse sample
use_cross_aug: False
cross_prob: 0.5
cross_gene: 0.0
cross_kernel_size: 0.0
cross_max_features: 0.0