{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'timm.models' has no attribute 'convnext_xxlarge'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/server1-ailab/Desktop/Bach/X2-VLM/data_testing.ipynb Cell 1\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2241445f56696e685f34384742227d/home/server1-ailab/Desktop/Bach/X2-VLM/data_testing.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtimm\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2241445f56696e685f34384742227d/home/server1-ailab/Desktop/Bach/X2-VLM/data_testing.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m timm\u001b[39m.\u001b[39;49mmodels\u001b[39m.\u001b[39;49mconvnext_xxlarge\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'timm.models' has no attribute 'convnext_xxlarge'"
     ]
    }
   ],
   "source": [
    "import timm\n",
    "\n",
    "timm.models.con"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textaugment import Wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the quick brown fox jumps over the lazy weenie\n"
     ]
    }
   ],
   "source": [
    "text = \"The quick brown fox jumps over the lazy dog\"\n",
    "\n",
    "t = Wordnet(v=True, n=True, p=0.5)\n",
    "print(t.augment(text, top_n=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.test.utils import datapath\n",
    "\n",
    "pretrained_path = datapath('/home/server-96gb-ailab/Desktop/Bach/Pedestrian-Matching/checkpoint/cc.en.300.bin.gz')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mgensim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfasttext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_facebook_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/bach_pytorch/lib/python3.11/site-packages/gensim/models/fasttext.py:728\u001b[0m, in \u001b[0;36mload_facebook_model\u001b[0;34m(path, encoding)\u001b[0m\n\u001b[1;32m    666\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_facebook_model\u001b[39m(path, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    667\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Load the model from Facebook's native fasttext `.bin` output file.\u001b[39;00m\n\u001b[1;32m    668\u001b[0m \n\u001b[1;32m    669\u001b[0m \u001b[38;5;124;03m    Notes\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    726\u001b[0m \n\u001b[1;32m    727\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 728\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_load_fasttext_format\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfull_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/bach_pytorch/lib/python3.11/site-packages/gensim/models/fasttext.py:808\u001b[0m, in \u001b[0;36m_load_fasttext_format\u001b[0;34m(model_file, encoding, full_model)\u001b[0m\n\u001b[1;32m    789\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Load the input-hidden weight matrix from Facebook's native fasttext `.bin` output files.\u001b[39;00m\n\u001b[1;32m    790\u001b[0m \n\u001b[1;32m    791\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    805\u001b[0m \n\u001b[1;32m    806\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    807\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m utils\u001b[38;5;241m.\u001b[39mopen(model_file, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m fin:\n\u001b[0;32m--> 808\u001b[0m     m \u001b[38;5;241m=\u001b[39m \u001b[43mgensim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fasttext_bin\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfull_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfull_model\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    810\u001b[0m model \u001b[38;5;241m=\u001b[39m FastText(\n\u001b[1;32m    811\u001b[0m     vector_size\u001b[38;5;241m=\u001b[39mm\u001b[38;5;241m.\u001b[39mdim,\n\u001b[1;32m    812\u001b[0m     window\u001b[38;5;241m=\u001b[39mm\u001b[38;5;241m.\u001b[39mws,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    821\u001b[0m     max_n\u001b[38;5;241m=\u001b[39mm\u001b[38;5;241m.\u001b[39mmaxn,\n\u001b[1;32m    822\u001b[0m )\n\u001b[1;32m    823\u001b[0m model\u001b[38;5;241m.\u001b[39mcorpus_total_words \u001b[38;5;241m=\u001b[39m m\u001b[38;5;241m.\u001b[39mntokens\n",
      "File \u001b[0;32m~/miniconda3/envs/bach_pytorch/lib/python3.11/site-packages/gensim/models/_fasttext_bin.py:345\u001b[0m, in \u001b[0;36mload\u001b[0;34m(fin, encoding, full_model)\u001b[0m\n\u001b[1;32m    342\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m new_format:\n\u001b[1;32m    343\u001b[0m     model\u001b[38;5;241m.\u001b[39mupdate(dim\u001b[38;5;241m=\u001b[39mmagic, ws\u001b[38;5;241m=\u001b[39mversion)\n\u001b[0;32m--> 345\u001b[0m raw_vocab, vocab_size, nwords, ntokens \u001b[38;5;241m=\u001b[39m \u001b[43m_load_vocab\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_format\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    346\u001b[0m model\u001b[38;5;241m.\u001b[39mupdate(raw_vocab\u001b[38;5;241m=\u001b[39mraw_vocab, vocab_size\u001b[38;5;241m=\u001b[39mvocab_size, nwords\u001b[38;5;241m=\u001b[39mnwords, ntokens\u001b[38;5;241m=\u001b[39mntokens)\n\u001b[1;32m    348\u001b[0m vectors_ngrams \u001b[38;5;241m=\u001b[39m _load_matrix(fin, new_format\u001b[38;5;241m=\u001b[39mnew_format)\n",
      "File \u001b[0;32m~/miniconda3/envs/bach_pytorch/lib/python3.11/site-packages/gensim/models/_fasttext_bin.py:213\u001b[0m, in \u001b[0;36m_load_vocab\u001b[0;34m(fin, new_format, encoding)\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m char_byte \u001b[38;5;241m!=\u001b[39m _END_OF_WORD_MARKER:\n\u001b[1;32m    212\u001b[0m     word_bytes\u001b[38;5;241m.\u001b[39mwrite(char_byte)\n\u001b[0;32m--> 213\u001b[0m     char_byte \u001b[38;5;241m=\u001b[39m \u001b[43mfin\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    215\u001b[0m word_bytes \u001b[38;5;241m=\u001b[39m word_bytes\u001b[38;5;241m.\u001b[39mgetvalue()\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/bach_pytorch/lib/python3.11/gzip.py:301\u001b[0m, in \u001b[0;36mGzipFile.read\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m    299\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01merrno\u001b[39;00m\n\u001b[1;32m    300\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(errno\u001b[38;5;241m.\u001b[39mEBADF, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread() on write-only GzipFile object\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 301\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer\u001b[38;5;241m.\u001b[39mread(size)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = gensim.models.fasttext.load_facebook_model(pretrained_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textaugment import Word2vec\n",
    "\n",
    "t = Word2vec(model = model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"The man wears a white and black shirt ,black pants with red and white sneakers he walks holding an item inside his hand.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/server-96gb-ailab/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['man', 'shirt', 'pants', 'sneakers', 'item', 'hand']\n"
     ]
    }
   ],
   "source": [
    "tokens = word_tokenize(sentence)\n",
    "tagged_tokens = pos_tag(tokens)\n",
    "\n",
    "nouns = [word for word, tag in tagged_tokens if tag in ('NN', 'NNS', 'NNP', 'NNPS')]\n",
    "print(nouns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from googletrans import Translator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'group'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m translator \u001b[38;5;241m=\u001b[39m Translator()\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtranslator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranslate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mHow high is the sky?\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/bach_pytorch/lib/python3.11/site-packages/googletrans/client.py:182\u001b[0m, in \u001b[0;36mTranslator.translate\u001b[0;34m(self, text, dest, src, **kwargs)\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[1;32m    181\u001b[0m origin \u001b[38;5;241m=\u001b[39m text\n\u001b[0;32m--> 182\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_translate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;66;03m# this code will be updated when the format is changed.\u001b[39;00m\n\u001b[1;32m    185\u001b[0m translated \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([d[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m d[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m data[\u001b[38;5;241m0\u001b[39m]])\n",
      "File \u001b[0;32m~/miniconda3/envs/bach_pytorch/lib/python3.11/site-packages/googletrans/client.py:78\u001b[0m, in \u001b[0;36mTranslator._translate\u001b[0;34m(self, text, dest, src, override)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_translate\u001b[39m(\u001b[38;5;28mself\u001b[39m, text, dest, src, override):\n\u001b[0;32m---> 78\u001b[0m     token \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtoken_acquirer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     79\u001b[0m     params \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39mbuild_params(query\u001b[38;5;241m=\u001b[39mtext, src\u001b[38;5;241m=\u001b[39msrc, dest\u001b[38;5;241m=\u001b[39mdest,\n\u001b[1;32m     80\u001b[0m                                 token\u001b[38;5;241m=\u001b[39mtoken, override\u001b[38;5;241m=\u001b[39moverride)\n\u001b[1;32m     82\u001b[0m     url \u001b[38;5;241m=\u001b[39m urls\u001b[38;5;241m.\u001b[39mTRANSLATE\u001b[38;5;241m.\u001b[39mformat(host\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pick_service_url())\n",
      "File \u001b[0;32m~/miniconda3/envs/bach_pytorch/lib/python3.11/site-packages/googletrans/gtoken.py:194\u001b[0m, in \u001b[0;36mTokenAcquirer.do\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdo\u001b[39m(\u001b[38;5;28mself\u001b[39m, text):\n\u001b[0;32m--> 194\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    195\u001b[0m     tk \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39macquire(text)\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tk\n",
      "File \u001b[0;32m~/miniconda3/envs/bach_pytorch/lib/python3.11/site-packages/googletrans/gtoken.py:62\u001b[0m, in \u001b[0;36mTokenAcquirer._update\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;66;03m# this will be the same as python code after stripping out a reserved word 'var'\u001b[39;00m\n\u001b[0;32m---> 62\u001b[0m code \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mRE_TKK\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroup\u001b[49m(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvar \u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     63\u001b[0m \u001b[38;5;66;03m# unescape special ascii characters such like a \\x3d(=)\u001b[39;00m\n\u001b[1;32m     64\u001b[0m code \u001b[38;5;241m=\u001b[39m code\u001b[38;5;241m.\u001b[39mencode()\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124municode-escape\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'group'"
     ]
    }
   ],
   "source": [
    "translator = Translator()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bach_pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
